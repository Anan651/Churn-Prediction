# -*- coding: utf-8 -*-
"""Etisalat_UseCase.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19e70CM1LhJPJkW5PaTTc8q8Ei1Bw6-6_

**1.Read dataset**
"""

import pandas as pd
WA = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
WA

"""**2. Data cleaning and EDA**"""

WA.info()

WA= WA.drop("customerID", axis=1)

WA.columns = WA.columns.str.strip()

from sklearn.preprocessing import LabelEncoder
encoders = {}
for col in WA.columns:
    if WA[col].dtype == 'object':
        le = LabelEncoder()
        WA[col] = le.fit_transform(WA[col].astype(str))
        encoders[col] = le

"""Methods to see relationship between features"""

correlation_matrix = WA.corr().abs()
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()

"""
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
X = WA.drop("Churn", axis=1)
y = WA["Churn"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(X_train, y_train)
importances = model.feature_importances_
feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)
feat_importance.plot(kind='bar', figsize=(10,5))
plt.title("Feature Importance from XGBoost")
plt.show()
"""

correlation_with_target = WA.corr(method='pearson')["Churn"].drop("Churn")
print("Correlation with Churn:\n", correlation_with_target)
threshold = 0.04
features_to_keep = correlation_with_target[abs(correlation_with_target) >= threshold].index
features_to_drop = correlation_with_target[abs(correlation_with_target) < threshold].index
print("Features to DROP (< threshold):", list(features_to_drop))

WA = WA.drop(["gender", "Phone_Service", "Dual","Streaming_TV", "Streaming_Movies", "Total_Charges"],axis=1)

import matplotlib.pyplot as plt
WA.hist(figsize=(14, 10), bins=30)
plt.suptitle("Feature Distributions", fontsize=12)
plt.show()

"""Detect if there is outliers

from scipy.stats import zscore
WA["z_score"] = zscore(WA["Monthly_Charges"])
outliers = WA[(WA["z_score"] > 3) | (WA["z_score"] < -3)]
print(f"Number of outliers: {len(outliers)}")
"""

print(WA['Churn'].value_counts())

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
X = WA.drop("Churn", axis=1)
y = WA["Churn"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test[numeric_features] = scaler.transform(X_test[numeric_features])

"""**3.SVC model with upsampling**


"""

from sklearn.svm import SVC
svm_model = SVC(kernel='rbf', random_state=42)
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - SVM (Upsampling Only)")
plt.show()

"""**4.naive_bayes**"""

from sklearn.naive_bayes import GaussianNB
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

y_pred = nb_model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Naive Bayes (Upsampling Only)")
plt.show()

"""**5.Logistic Regression model**"""

X = WA.drop("Churn", axis=1)
y = WA["Churn"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt
y_proba = model.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_proba)
print("Test ROC AUC:", roc_auc)
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

from sklearn.model_selection import learning_curve
import numpy as np
train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)
train_mean = np.mean(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
plt.plot(train_sizes, train_mean, label="Training score")
plt.plot(train_sizes, test_mean, label="Validation score")
plt.xlabel("Training Set Size")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Learning Curve - Logistic Regression")
plt.show()

"""Logistic regression using Class Weights"""

model_weight = LogisticRegression(max_iter=1000,class_weight='balanced')
model_weight.fit(X_train, y_train)
y_pred = model_weight.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt
y_proba = model.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_proba)
print("Test ROC AUC:", roc_auc)
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

from sklearn.decomposition import PCA
y_pred_log = model_weight.predict(X_test)
pca = PCA(n_components=2)
X_test_2d = pca.fit_transform(X_test)
df_plot = pd.DataFrame({
    'PCA1': X_test_2d[:, 0],
    'PCA2': X_test_2d[:, 1],
    'Actual': y_test.values,
    'Predicted': y_pred
})
plt.figure(figsize=(10,5))
plt.subplot(1, 2, 1)
sns.scatterplot(data=df_plot, x='PCA1', y='PCA2', hue='Actual', palette='Set1', alpha=0.7)
plt.title("Actual Groups")

plt.subplot(1, 2, 2)
sns.scatterplot(data=df_plot, x='PCA1', y='PCA2', hue='Predicted', palette='Set1', alpha=0.7)
plt.title("Logistic Regression Predicted Groups")

plt.tight_layout()
plt.show()

"""Logistic regression with upsampling

"""

!pip install joblib
from sklearn.utils import resample
from google.colab import files
majority_class = WA[WA.Churn == 0]
minority_class = WA[WA.Churn == 1]
minority_upsampled = resample(
    minority_class,
    replace=True,
    n_samples=len(majority_class),
    random_state=42
)

df_upsampled = pd.concat([majority_class, minority_upsampled])
df_upsampled = df_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)
X_balanced = df_upsampled.drop("Churn", axis=1)
y_balanced = df_upsampled["Churn"]
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train, y_train)

feature_order = X_balanced.columns.tolist()
joblib.dump((log_reg, encoders, feature_order), "log_reg_with_encoders.pkl")
files.download("log_reg_with_encoders.pkl")

y_pred = log_reg.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'],
            yticklabels=['No Churn', 'Churn'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression (Upsampling Only)")
plt.show()

print (feature_order)